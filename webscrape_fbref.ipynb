{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zGOV7uSk8ZT"
   },
   "source": [
    "This notebook is to scrape football data from fbref.com\n",
    "\n",
    "Much of the scraping code is taken from this repository: https://github.com/chmartin/FBref_EPL.\n",
    "\n",
    "Run the first cell and then the further cells to get data for whichever leagues you want.\n",
    "\n",
    "All data is courtesy of StatsBomb via FBref. Find me on Twitter @pathaleee!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "2qYGN7pfk3gK"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys, getopt\n",
    "import csv\n",
    "import time\n",
    "import traceback\n",
    "from functools import wraps\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "\n",
    "#Functions to get the data in a dataframe using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE Most complete data seems to appear after 2018 (eg. Distance for shooting in Championship)\n",
    "\n",
    "# La Liga: 12, Segunda Div: 17, EPL: 9, Championship: 10\n",
    "\n",
    "COMPETITION_MAPPING = {\n",
    "    # 'ENG': {\n",
    "    #     9: 'Premier-League',\n",
    "    #     10: 'Championship'\n",
    "    # },\n",
    "    'SPA': {\n",
    "        12: 'La-Liga',\n",
    "        17: 'Segunda-Division'\n",
    "    },\n",
    "    'GER': {\n",
    "        20: 'Bundesliga',\n",
    "        33: '2-Bundesliga'\n",
    "    },\n",
    "    'ITA': {\n",
    "        11: 'Serie-A',\n",
    "        18: 'Serie-B'\n",
    "    },\n",
    "    'FRA': {\n",
    "        13: 'Ligue-1',\n",
    "        60: 'Ligue-2'\n",
    "    }\n",
    "}\n",
    "\n",
    "MAX_RETRIES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeasonData:\n",
    "\n",
    "    categories = ['stats', 'keepers', 'keepersadv', 'shooting', 'passing', 'passing_types', 'gca', 'defense', 'possession', 'misc']\n",
    "\n",
    "    def __init__(self, year, country):\n",
    "        self.country = country\n",
    "        self.year = year\n",
    "        self.comp_ids = list(COMPETITION_MAPPING[country].keys())\n",
    "\n",
    "        self.urls = {\n",
    "            1: {\n",
    "                'pre': f\"https://fbref.com/en/comps/{self.comp_ids[0]}/{year}-{year+1}/\", # season table url\n",
    "                'suf': f\"/{year}-{year+1}-{COMPETITION_MAPPING[country][self.comp_ids[0]]}-Stats\" # get data url\n",
    "            },\n",
    "            2: {\n",
    "                'pre': f\"https://fbref.com/en/comps/{self.comp_ids[1]}/{year}-{year+1}/\", # season table url\n",
    "                'suf': f\"/{year}-{year+1}-{COMPETITION_MAPPING[country][self.comp_ids[1]]}-Stats\" # get data url\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.table_urls = [div_urls['pre'] for div_urls in self.urls.values()]\n",
    "        self.promoted_teams = []\n",
    "        self.relegated_teams = []\n",
    "        self.df_team = None\n",
    "\n",
    "    def catch_too_many_requests(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for i in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except HTTPError as http_err:\n",
    "                    if hasattr(http_err, 'response') and http_err.response.status_code == 429:\n",
    "                        print(\"Rate limit exceeded.\")\n",
    "                    else:\n",
    "                        print(f\"HTTP error occurred: {http_err}\" + \", retrying\" if i < MAX_RETRIES else \"\")\n",
    "        return wrapper\n",
    "\n",
    "    @catch_too_many_requests\n",
    "    def get_promoted_teams(self):\n",
    "        res = requests.get(self.urls[2]['pre'])\n",
    "        res.raise_for_status()\n",
    "        comm = re.compile(\"<!--|-->\")\n",
    "        soup = BeautifulSoup(comm.sub(\"\",res.text),'lxml')    \n",
    "        all_tables = soup.findAll(\"tbody\")\n",
    "        results_table = all_tables[0]\n",
    "        rows_teams = results_table.find_all('tr')\n",
    "        for row in rows_teams:\n",
    "            self.find_special_teams(row, 'promote')\n",
    "            \n",
    "    @catch_too_many_requests\n",
    "    def get_relegated_teams(self):\n",
    "        res = requests.get(self.urls[1]['pre'])\n",
    "        res.raise_for_status()\n",
    "        comm = re.compile(\"<!--|-->\")\n",
    "        soup = BeautifulSoup(comm.sub(\"\",res.text),'lxml')    \n",
    "        all_tables = soup.findAll(\"tbody\")\n",
    "        results_table = all_tables[0]\n",
    "        rows_teams = results_table.find_all('tr')\n",
    "        for row in rows_teams:\n",
    "            self.find_special_teams(row, 'relegate')\n",
    "\n",
    "    def find_special_teams(self, row, class_name): # promoted or relegated\n",
    "        if(row.find(lambda tag: tag.name == 'th' and tag.has_attr('class') \\\n",
    "            and class_name in tag['class']) != None):\n",
    "            team_td = row.find('td', {'data-stat': 'team'})\n",
    "            team_added = 0\n",
    "            if team_td:\n",
    "                team_name = team_td.find('a').text.strip()\n",
    "                if team_name:\n",
    "                    # print(team_name)\n",
    "                    if class_name == 'promote':\n",
    "                        self.promoted_teams.append(team_name)\n",
    "                    else:\n",
    "                        self.relegated_teams.append(team_name)\n",
    "                    team_added = 1\n",
    "            if team_added == 0:\n",
    "                print(f\"{class_name}d team found but was not appended to {class_name}d teams array\")\n",
    "\n",
    "    @staticmethod\n",
    "    @catch_too_many_requests\n",
    "    def get_team_table(url):\n",
    "        # print(url)\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        ## The next two lines get around the issue with comments breaking the parsing.\n",
    "        comm = re.compile(\"<!--|-->\")\n",
    "        soup = BeautifulSoup(comm.sub(\"\",res.text),'lxml')    \n",
    "        all_tables = soup.findAll(\"tbody\")\n",
    "        team_table = all_tables[0]\n",
    "        return team_table\n",
    "\n",
    "    def get_frame_team(self, team_table, url):\n",
    "        pre_df_squad = dict()\n",
    "        rows_squad = team_table.find_all('tr')\n",
    "        for row in rows_squad:\n",
    "            if(row.find('th',{\"scope\":\"row\"}) != None) and row.find('th',{\"data-stat\":\"team\"}):\n",
    "                name = row.find('th',{\"data-stat\":\"team\"}).text.strip().encode().decode(\"utf-8\")\n",
    "                if (url == self.urls[2]['pre'] and name not in self.promoted_teams) or \\\n",
    "                    (url == self.urls[1]['pre'] and name in self.relegated_teams):\n",
    "                    continue\n",
    "                # print(f\"Team found: {name}\")\n",
    "                if 'squad' in pre_df_squad:\n",
    "                    pre_df_squad['squad'].append(name)\n",
    "                else:\n",
    "                    pre_df_squad['squad'] = [name]\n",
    "                for f in [td.get('data-stat') for td in row.find_all('td')]:\n",
    "                    cell = row.find(\"td\",{\"data-stat\": f})\n",
    "                    a = cell.text.strip().encode()\n",
    "                    text=a.decode(\"utf-8\")\n",
    "                    if(text == ''):\n",
    "                        text = None\n",
    "                    if f in pre_df_squad:\n",
    "                        pre_df_squad[f].append(text)\n",
    "                    else:\n",
    "                        pre_df_squad[f] = [text]\n",
    "        df_squad = pd.DataFrame.from_dict(pre_df_squad)\n",
    "    #     print(df_squad.columns) # print columns for each table\n",
    "        return df_squad\n",
    "\n",
    "    def frame_for_category_team(self, category):\n",
    "        df_divs_array = []\n",
    "        for div_urls in self.urls.values(): # first div url, second div url\n",
    "            team_table = self.get_team_table(div_urls['pre'] + category + div_urls['suf'])\n",
    "            df_team = self.get_frame_team(team_table, div_urls['pre'])\n",
    "            df_divs_array.append(df_team)\n",
    "        \n",
    "        return pd.concat(df_divs_array)\n",
    "\n",
    "    #Function to get team-wise data accross all categories as mentioned above\n",
    "    def get_team_data(self):\n",
    "        df_array = []\n",
    "        for category in self.categories:\n",
    "            df_array.append(self.frame_for_category_team(category))\n",
    "            time.sleep(5)\n",
    "        df = pd.concat(df_array, axis=1)\n",
    "        self.df_team = df.loc[:,~df.columns.duplicated()].copy()\n",
    "        self.df_team['season_start_year'] = self.year\n",
    "        self.df_team['season_end_year'] = self.year + 1\n",
    "    \n",
    "    def save_to_csv(self):\n",
    "        try:\n",
    "            self.df_team.to_csv(f\"./data/teams/raw/{self.country}{self.year}_teams_for_{self.year+1}.csv\",index=False)\n",
    "            print(f\"Saved successfully ({self.year})\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "id": "5e_hIIV3mYP-",
    "outputId": "613375c0-e015-4e4e-f18d-ff8778e13a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved successfully (2018)\n",
      "Saved successfully (2019)\n",
      "Saved successfully (2020)\n",
      "Saved successfully (2021)\n",
      "Saved successfully (2022)\n",
      "Saved successfully (2018)\n",
      "Saved successfully (2019)\n",
      "Saved successfully (2020)\n",
      "Saved successfully (2021)\n",
      "Saved successfully (2022)\n",
      "Saved successfully (2018)\n",
      "Saved successfully (2019)\n",
      "Saved successfully (2020)\n",
      "Saved successfully (2021)\n",
      "Saved successfully (2022)\n",
      "Saved successfully (2018)\n",
      "Saved successfully (2019)\n",
      "Saved successfully (2020)\n",
      "Saved successfully (2021)\n",
      "Saved successfully (2022)\n"
     ]
    }
   ],
   "source": [
    "#This cell is to get the data FOR all teams in any competition\n",
    "\n",
    "#Go to the 'Standard stats' page of the league\n",
    "#For Premier League 2020/21, the link is this: https://fbref.com/en/comps/9/stats/Premier-League-Stats\n",
    "#Remove the 'stats', and pass the first and third part of the link as parameters like below\n",
    "\n",
    "# NOTE: may need to add delays between requests to prevent 429 (gettting blocked by fbref)\n",
    "\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "for country in COMPETITION_MAPPING.keys():\n",
    "    for year in range(2018, 2023):\n",
    "\n",
    "        season_data = SeasonData(year, country)\n",
    "\n",
    "        season_data.get_promoted_teams()\n",
    "        season_data.get_relegated_teams()\n",
    "\n",
    "        season_data.get_team_data() # sets self.df_team\n",
    "\n",
    "        season_data.save_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Scrape_FBref.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
